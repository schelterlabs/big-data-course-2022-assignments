{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2fe953e",
   "metadata": {},
   "source": [
    "# Setup Test\n",
    "\n",
    "The goal of this notebook is to make sure that your local setup works and that you can successfully connect to the autograding server that we provide for later assignments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9921a77e",
   "metadata": {},
   "source": [
    "### Before you begin - automark\n",
    "\n",
    "To check whether the code you've written is correct, we'll use **automark**. For this, we created for each of you an account with the username being your student number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b0f890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import automark as am\n",
    "\n",
    "# fill in you student number as your username\n",
    "am.configure(username='0')\n",
    "\n",
    "# to check your progress, you can run this function\n",
    "am.get_progress()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3c961b",
   "metadata": {},
   "source": [
    "### SQL with DuckDB - Setup test\n",
    "\n",
    "First, we test whether the embedded database [DuckDB](https://duckdb.org/) works on your machine, which lets us write SQL queries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c21fa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "sailors_data = {\n",
    "    'sid': [1, 2, 3],\n",
    "    'sname': [\"Fred\", \"Nancy\", \"Ji\"],\n",
    "    'experience': [7, 2, 8],\n",
    "    'age': [22, 39, 27]\n",
    "}\n",
    "\n",
    "sailors = pd.DataFrame.from_dict(sailors_data)\n",
    "\n",
    "sailors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2917addb",
   "metadata": {},
   "source": [
    "The following helper function allows us to run queries on the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa45079",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_local(query):\n",
    "    con = duckdb.connect(database=':memory:', read_only=False)\n",
    "    con.register('sailors', sailors)\n",
    "\n",
    "    result = con.execute(query).fetchdf()\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bdcb29",
   "metadata": {},
   "source": [
    "#### Test task\n",
    "\n",
    "In this test task, we compute the average experience of sailors that are less than 35 years old. Copy the following SQL query into the appropriate location in the `a0_t1_sailor_avg_experience` function below.\n",
    "\n",
    "`SELECT AVG(experience) FROM sailors WHERE age < 35;`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c36fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def a0_t1_sailor_avg_experience():\n",
    "    query = '''\n",
    "    REPLACE_THIS_TEXT_WITH_THE_SQL_QUERY    \n",
    "    '''\n",
    "\n",
    "    return query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf19961a",
   "metadata": {},
   "source": [
    "Now you can test the query on the local `sailors` data via the helper function. This should return a single tuple with an attribute `avg(experience)` and a value of 7.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc3d374",
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_local(a0_t1_sailor_avg_experience())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43869c57",
   "metadata": {},
   "source": [
    "Finally, you can have the autograding server test your function by executing the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d124ed7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "am.test_student_function(a0_t1_sailor_avg_experience)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e78a6d",
   "metadata": {},
   "source": [
    "### Dataflows with PySpark - Setup Test \n",
    "\n",
    "Next, we test whether you can run [PySpark](https://spark.apache.org/docs/latest/api/python/) programs locally on your computer. For that, we setup a local Pyspark session first.\n",
    "\n",
    "Note that you can ignore the following warnings that might occur when executing the next cell:\n",
    "\n",
    "```\n",
    "WARNING: An illegal reflective access operation has occurred\n",
    "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.2.0-bin-hadoop3.2/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
    "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
    "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
    "WARNING: All illegal access operations will be denied in a future release\n",
    "```\n",
    "\n",
    "and\n",
    "\n",
    "```\n",
    " WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab25d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .config(\"spark.driver.bindAddress\", \"127.0.0.1\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d3ceb1",
   "metadata": {},
   "source": [
    "Next, we turn our sailors data into a PySpark dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603eb12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sailors_df = spark.createDataFrame(sailors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f1aff6",
   "metadata": {},
   "source": [
    "#### Test task\n",
    "\n",
    "In this test task, we again compute the average experience of sailors that are less than 35 years old. Copy the following pyspark code into the appropriate location in the `a0_t2_sailor_avg_experience_pyspark` function below.\n",
    "\n",
    "`return sailors_data.filter(sailors_data['age'] < 35).agg({\"experience\": \"avg\"})`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffa27fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def a0_t2_sailor_avg_experience_pyspark(sailors_data):\n",
    "    # REPLACE THE LINE BELOW WITH THE PYSPARK CODE.\n",
    "    return sailors_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d1bd4e",
   "metadata": {},
   "source": [
    "Now you can test the spark program on the local `sailors_df` data. This should again return a single tuple with an attribute `avg(experience)` and a value of 7.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808dd4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = a0_t2_sailor_avg_experience_pyspark(sailors_df)\n",
    "result.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914fb73c",
   "metadata": {},
   "source": [
    "Finally, you can have the autograding server test your function by executing the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4a7737",
   "metadata": {},
   "outputs": [],
   "source": [
    "am.test_student_function(a0_t2_sailor_avg_experience_pyspark)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
